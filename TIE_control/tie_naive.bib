
@article{breukelen_efficient_2018,
	title = {Efficient design of cluster randomized trials with treatment-dependent costs and treatment-dependent unknown variances},
	volume = {37},
	copyright = {© 2018 The Authors. Statistics in Medicine published by John Wiley \& Sons Ltd.},
	issn = {1097-0258},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/sim.7824},
	doi = {10.1002/sim.7824},
	abstract = {Cluster randomized trials evaluate the effect of a treatment on persons nested within clusters, where treatment is randomly assigned to clusters. Current equations for the optimal sample size at the cluster and person level assume that the outcome variances and/or the study costs are known and homogeneous between treatment arms. This paper presents efficient yet robust designs for cluster randomized trials with treatment-dependent costs and treatment-dependent unknown variances, and compares these with 2 practical designs. First, the maximin design (MMD) is derived, which maximizes the minimum efficiency (minimizes the maximum sampling variance) of the treatment effect estimator over a range of treatment-to-control variance ratios. The MMD is then compared with the optimal design for homogeneous variances and costs (balanced design), and with that for homogeneous variances and treatment-dependent costs (cost-considered design). The results show that the balanced design is the MMD if the treatment-to control cost ratio is the same at both design levels (cluster, person) and within the range for the treatment-to-control variance ratio. It still is highly efficient and better than the cost-considered design if the cost ratio is within the range for the squared variance ratio. Outside that range, the cost-considered design is better and highly efficient, but it is not the MMD. An example shows sample size calculation for the MMD, and the computer code (SPSS and R) is provided as supplementary material. The MMD is recommended for trial planning if the study costs are treatment-dependent and homogeneity of variances cannot be assumed.},
	language = {en},
	number = {21},
	urldate = {2019-08-15},
	journal = {Statistics in Medicine},
	author = {Breukelen, Gerard J. P. van and Candel, Math J. J. M.},
	year = {2018},
	keywords = {cluster randomized trial, heterogeneous variance, maximin design, optimal design, sample size, study costs},
	pages = {3027--3046},
	file = {Full Text PDF:/Users/jnugent/Zotero/storage/6Q8AKKB9/Breukelen and Candel - 2018 - Efficient design of cluster randomized trials with.pdf:application/pdf;Snapshot:/Users/jnugent/Zotero/storage/4AA4M8KQ/sim.html:text/html}
}

@article{moon_effect_2017,
	title = {The {Effect} of {Nursing} {Quality} {Improvement} and {Mobile} {Health} {Interventions} on {Infant} {Sleep} {Practices}: {A} {Randomized} {Clinical} {Trial}},
	volume = {318},
	issn = {1538-3598},
	shorttitle = {The {Effect} of {Nursing} {Quality} {Improvement} and {Mobile} {Health} {Interventions} on {Infant} {Sleep} {Practices}},
	doi = {10.1001/jama.2017.8982},
	abstract = {Importance: Inadequate adherence to recommendations known to reduce the risk of sudden unexpected infant death has contributed to a slowing in the decline of these deaths.
Objective: To assess the effectiveness of 2 interventions separately and combined to promote infant safe sleep practices compared with control interventions.
Design, Setting, and Participants: Four-group cluster randomized clinical trial of mothers of healthy term newborns who were recruited between March 2015 and May 2016 at 16 US hospitals with more than 100 births annually. Data collection ended in October 2016.
Interventions: All participants were beneficiaries of a nursing quality improvement campaign in infant safe sleep practices (intervention) or breastfeeding (control), and then received a 60-day mobile health program, in which mothers received frequent emails or text messages containing short videos with educational content about infant safe sleep practices (intervention) or breastfeeding (control) and queries about infant care practices.
Main Outcomes and Measures: The primary outcome was maternal self-reported adherence to 4 infant safe sleep practices of sleep position (supine), sleep location (room sharing without bed sharing), soft bedding use (none), and pacifier use (any); data were collected by maternal survey when the infant was aged 60 to 240 days.
Results: Of the 1600 mothers who were randomized to 1 of 4 groups (400 per group), 1263 completed the survey (78.9\%). The mean (SD) maternal age was 28.1 years (5.8 years) and 32.8\% of respondents were non-Hispanic white, 32.3\% Hispanic, 27.2\% non-Hispanic black, and 7.7\% other race/ethnicity. The mean (SD) infant age was 11.2 weeks (4.4 weeks) and 51.2\% were female. In the adjusted analyses, mothers receiving the safe sleep mobile health intervention had higher prevalence of placing their infants supine compared with mothers receiving the control mobile health intervention (89.1\% vs 80.2\%, respectively; adjusted risk difference, 8.9\% [95\% CI, 5.3\%-11.7\%]), room sharing without bed sharing (82.8\% vs 70.4\%; adjusted risk difference, 12.4\% [95\% CI, 9.3\%-15.1\%]), no soft bedding use (79.4\% vs 67.6\%; adjusted risk difference, 11.8\% [95\% CI, 8.1\%-15.2\%]), and any pacifier use (68.5\% vs 59.8\%; adjusted risk difference, 8.7\% [95\% CI, 3.9\%-13.1\%]). The independent effect of the nursing quality improvement intervention was not significant for all outcomes. Interactions between the 2 interventions were only significant for the supine sleep position.
Conclusions and Relevance: Among mothers of healthy term newborns, a mobile health intervention, but not a nursing quality improvement intervention, improved adherence to infant safe sleep practices compared with control interventions. Whether widespread implementation is feasible or if it reduces sudden and unexpected infant death rates remains to be studied.
Trial Registration: clinicaltrials.gov Identifier: NCT01713868.},
	language = {eng},
	number = {4},
	journal = {JAMA},
	author = {Moon, Rachel Y. and Hauck, Fern R. and Colson, Eve R. and Kellams, Ann L. and Geller, Nicole L. and Heeren, Timothy and Kerr, Stephen M. and Drake, Emily E. and Tanabe, Kawai and McClain, Mary and Corwin, Michael J.},
	year = {2017},
	pmid = {28742913},
	pmcid = {PMC5593130},
	keywords = {Humans, Adult, Attitude to Health, Bedding and Linens, Breast Feeding, Female, Infant Care, Infant, Newborn, Male, Mothers, Nursing Care, Quality Improvement, Sleep, Sudden Infant Death, Supine Position, Telemedicine},
	pages = {351--359},
	file = {Full Text:/Users/jnugent/Zotero/storage/LU9HLMNH/Moon et al. - 2017 - The Effect of Nursing Quality Improvement and Mobi.pdf:application/pdf}
}

@article{vinereanu_multifaceted_2017,
	title = {A multifaceted intervention to improve treatment with oral anticoagulants in atrial fibrillation ({IMPACT}-{AF}): an international, cluster-randomised trial},
	volume = {390},
	issn = {0140-6736, 1474-547X},
	shorttitle = {A multifaceted intervention to improve treatment with oral anticoagulants in atrial fibrillation ({IMPACT}-{AF})},
	url = {https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(17)32165-7/abstract},
	doi = {10.1016/S0140-6736(17)32165-7},
	abstract = {{\textless}h2{\textgreater}Summary{\textless}/h2{\textgreater}{\textless}h3{\textgreater}Background{\textless}/h3{\textgreater}{\textless}p{\textgreater}Oral anticoagulation is underused in patients with atrial fibrillation. We assessed the impact of a multifaceted educational intervention, versus usual care, on oral anticoagulant use in patients with atrial fibrillation.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Methods{\textless}/h3{\textgreater}{\textless}p{\textgreater}This study was a two-arm, prospective, international, cluster-randomised, controlled trial. Patients were included who had atrial fibrillation and an indication for oral anticoagulation. Clusters were randomised (1:1) to receive a quality improvement educational intervention (intervention group) or usual care (control group). Randomisation was carried out centrally, using the eClinicalOS electronic data capture system. The intervention involved education of providers and patients, with regular monitoring and feedback. The primary outcome was the change in the proportion of patients treated with oral anticoagulants from baseline assessment to evaluation at 1 year. The trial is registered at ClinicalTrials.gov, number NCT02082548.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Findings{\textless}/h3{\textgreater}{\textless}p{\textgreater}2281 patients from five countries (Argentina, n=343; Brazil, n=360; China, n=586; India, n=493; and Romania, n=499) were enrolled from 48 clusters between June 11, 2014, and Nov 13, 2016. Follow-up was at a median of 12·0 months (IQR 11·8–12·2). Oral anticoagulant use increased in the intervention group from 68\% (804 of 1184 patients) at baseline to 80\% (943 of 1184 patients) at 1 year (difference 12\%), whereas in the control group it increased from 64\% (703 of 1092 patients) at baseline to 67\% (732 of 1092 patients) at 1 year (difference 3\%). Absolute difference in the change between groups was 9·1\% (95\% CI 3·8–14·4); odds ratio of change in the use of oral anticoagulation between groups was 3·28 (95\% CI 1·67–6·44; adjusted p value=0·0002). Kaplan-Meier estimates showed a reduction in the secondary outcome of stroke in the intervention versus control groups (HR 0·48, 95\% CI 0·23–0·99; log-rank p value=0·0434).{\textless}/p{\textgreater}{\textless}h3{\textgreater}Interpretation{\textless}/h3{\textgreater}{\textless}p{\textgreater}A multifaceted and multilevel educational intervention, aimed to improve use of oral anticoagulation in patients with atrial fibrillation and at risk for stroke, resulted in a significant increase in the proportion of patients treated with oral anticoagulants. Such an intervention has the potential to improve stroke prevention around the world for patients with atrial fibrillation.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Funding{\textless}/h3{\textgreater}{\textless}p{\textgreater}Bayer, Boehringer Ingelheim, Bristol-Myers Squibb, Daiichi Sankyo, and Pfizer.{\textless}/p{\textgreater}},
	language = {English},
	number = {10104},
	urldate = {2019-08-15},
	journal = {The Lancet},
	author = {Vinereanu, Dragos and Lopes, Renato D. and Bahit, M. Cecilia and Xavier, Denis and Jiang, Jie and Al-Khalidi, Hussein R. and He, Wensheng and Xian, Ying and Ciobanu, Andrea O. and Kamath, Deepak Y. and Fox, Kathleen A. and Rao, Meena P. and Pokorney, Sean D. and Berwanger, Otavio and Tajer, Carlos and Silva, Pedro G. M. de Barros e and Roettig, Mayme L. and Huo, Yong and Granger, Christopher B. and Carbajales, Justo and Gómez, Javier Neri Ceferino and Principato, Mario Bruno and Wulffen, María Alejandra Von and Acunzo, Jorge Galperín Rafael Salvador and Bonato, Ricardo Renato and Ciampi, Natalia and Marani, Alberto Babil and Panigadi, Cristian Gustavo and Pastura, Silvia Gabriela and Onetto, Leonardo Martín and Moya, Cecilia Rafaela and Budassi, Nadia and Valle, Marisol and Camerini, Daniel and Monjes, Enrique and Zabala, Federico and Ricart, Juan Pablo and Medesani, Luis and Campos, Eduardo Noe Ortuño and Ferroni, Fabián and Torres, Mariana Foa and Fassi, Daniel Omar and Bosio, Fernando Javier Díaz and Baztarrica, Gabriel Edgardo Pérez and Infantas, Teresa Zúñiga and Perlo, Daniela and García, Celso Fernando and Durán, Rubén García and Durán, Luisina García and Pettinari, Cecilia Alejandra and Vico, Marisa Liliana and Lanchiotti, Paulina Virginia and Gómez, Mariela Soledad and Poy, Carlos Alberto and Grazziani, Franco Sebastián and Laspina, Marcela Julieta and Poy, María Laura and Bahit, María Cecilia and Tajer, Carlos and García, Marilia and Lopes, Renato D. and Silva, Pedro Gabriel Melo de Barros e and Berwanger, Otavio and Egydio, Flávia and Restelli, Elissa and Kawakami, Anelise and Soares, Tamara Colaiácovo and Valois, Mayara Vioto and Duarte, Tauane Bello and Barbosa, Lilian Mazza and Paola, Angelo Amato Vicenzo de and Pimenta, Thiago Librelon and Jeronimo, Gabriela Dal Moro and Costa, Bruna S. Fernandes da and Coutinho, Enia Lucia and Guerrero, Andressa Zulmira A. and Maia, Lilia Nigro and Nakazone, Marcelo Arruda and Lemos, Maria Angelica Teixeira and Costa, Osana Maria Coelho and Demore, Ana Paula and Brito, Roberta Parra and Melo, Camila Dal Bon and Góes, Nadielly Codonho and Lorenço, Osvaldo and Gonçalves, Luiz Otavio Maia and Nishiama, Kátia and Lima, Tiago Aparecido Maschio de and Backes, Luciano Marcelo and Deucher, Keyla Liliana Alves de Lima and Rodrigues, Milena Pozzatto and Baldissera, Dunnia Monisa and Reolão, José Basileu Caos and Santos, Tais Alves dos and Freisleben, Fernanda Michel Birck and Kaross, Níncia Lucca da Silveira and Montovani, Jéssika Tzervieczenski and Cantarelli, Maiara and Lucion, Aline and Amarante, Luciano do and Foscarini, Priscila and Perez, Claudia de Mello and França, Fernanda Ribeiro and Fialho, Lisa and Rey, Helena Cramer Veiga and God, Epotamenides Maria Good and Figueiredo, Estêvão Lanna and Werner, Gustavo Fonseca and Garcia, Jose Carlos de Faria and Azevedo, Bruna and Barbosa, Luiz Carlos Vianna and Pardi, Ernaldo and Oliveira, Márcia Domingos and Martinelli, Toshie and Cavalini, Roseli Gomes and Moraes, Michele Santos Montoni de and Filho, Adalberto Menezes Lorga and Palmegiani, Eduardo and Megid, Thiago Baccilli Cury and Queirantes, Clotildes S. P. and Cruz, Thamyres Santini Arroyo and He, Pengkang and Zhou, Xiaolan and Zhou, Na and Zhao, Mingzhong and Yu, Juan and Cheng, Yong and Wang, Lijun and Liu, Lili and Liu, Shuwang and Li, Lei and Li, Aihua and Yuan, Xiaochen and Xia, Guangwei and Wang, Zhirong and Li, Chengzong and Chen, Wensu and Tang, Qiang and Tang, Qunzhong and Xu, Weiting and Zhu, Xinyi and Hou, Bin and Ma, Wenjian and Wang, Chongquan and Jin, Qiaoyun and Wang, Jianan and Xie, Xiaojie and Joseph, Johny and Davidson, Deepak and Thomas, Joby K. and Kunjumon, Tony V. and Stephen, Tibin and Fatania, Kamlesh and Rathi, Gaurav and Garala, Kinjal and Doshi, Dhruval and Varghese, Kiron and Ma, Srilakshmi and Sheeba, Lumin and Kumar, Shantha and Rao, Malipeddi Bhaskara and Rao, Kodem Damodara and Vuriya, Anjan Kumar and Kumari, Mandula Padma and Khandelwal, Bidita and Dhakal, Mona and Srivastava, Nitin and Khatri, Dheeraj and Moktan, Shova and Gupta, Rajeev and Roy, Sanjeeb and Kumawat, Kapil and Sharma, Mukesh and Sharma, K. K. and Jathappa, Narendra and Lokesh, B. H. and Kariyappa, Shilpa and Leela, A. C. and Someshwara, K. C. and Desai, Soaham and Desai, Devangi and Patel, Kunj and Patel, Sujal and Bhartiya, Maulik and Mahanta, Bhupendra Narayan and Dutta, Dibya Jyoti and Rajkonwer, Ghanashyam and Gupta, Sandeep Kumar and Mishra, Ashok Kumar and Singh, Akansha and Kesarwani, Naveen and Kumar, Shivendra and Chioncel, Ovidiu and Balan, Adriana and Carstea, Nicolae and Chitoiu, Gabriel Tatu and Cornaciu, Stelian and Cinteza, Mircea and Rimbas, Roxana C. and Dimulescu, Doina and Ionescu, Luminita and Fruntelata, Ana and Dumitru, Nicoleta and Gaita, Dan and Pleava, Roxana and Iliesiu, Adriana and Uscoiu, Gabriela and Lighezan, Daniel and Buzas, Roxana and Sinescu, Crina J. and Avram, Ana-Maria and Baldea, Sorina and Galrinho, Ruxandra Dragoi and Magda, Stefania L. and Matei, Lavinia},
	month = oct,
	year = {2017},
	pmid = {28859942},
	pages = {1737--1746},
	file = {Snapshot:/Users/jnugent/Zotero/storage/2XZ4H7JX/fulltext.html:text/html}
}

@article{huang_targeted_2013,
	title = {Targeted versus {Universal} {Decolonization} to {Prevent} {ICU} {Infection}},
	volume = {368},
	issn = {0028-4793},
	url = {https://doi.org/10.1056/NEJMoa1207290},
	doi = {10.1056/NEJMoa1207290},
	abstract = {Health care–associated infection is a leading cause of preventable illness and death and often results from colonizing bacteria that overcome body defenses.1–5 Among the pathogens causing health care–associated infection, methicillin-resistant Staphylococcus aureus (MRSA) has been given priority as a target of reduction efforts because of its virulence and disease spectrum, multidrug-resistant profile, and increasing prevalence in health care settings, particularly among patients in the intensive care unit (ICU). Hospitals commonly screen patients in the ICU for nasal carriage of MRSA and use contact precautions with carriers.2–6 Nine states mandate such screening.7 Decolonization has been used to reduce transmission . . .},
	number = {24},
	urldate = {2019-08-15},
	journal = {New England Journal of Medicine},
	author = {Huang, Susan S. and Septimus, Edward and Kleinman, Ken and Moody, Julia and Hickok, Jason and Avery, Taliser R. and Lankiewicz, Julie and Gombosev, Adrijana and Terpstra, Leah and Hartford, Fallon and Hayden, Mary K. and Jernigan, John A. and Weinstein, Robert A. and Fraser, Victoria J. and Haffenreffer, Katherine and Cui, Eric and Kaganov, Rebecca E. and Lolans, Karen and Perlin, Jonathan B. and Platt, Richard},
	month = jun,
	year = {2013},
	pmid = {23718152},
	pages = {2255--2265},
	file = {Snapshot:/Users/jnugent/Zotero/storage/J4DVCRMR/NEJMoa1207290.html:text/html}
}

@article{li_comparing_2015,
	title = {Comparing denominator degrees of freedom approximations for the generalized linear mixed model in analyzing binary outcome in small sample cluster-randomized trials},
	volume = {15},
	issn = {1471-2288},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4458010/},
	doi = {10.1186/s12874-015-0026-x},
	abstract = {Background
Small number of clusters and large variation of cluster sizes commonly exist in cluster-randomized trials (CRTs) and are often the critical factors affecting the validity and efficiency of statistical analyses. F tests are commonly used in the generalized linear mixed model (GLMM) to test intervention effects in CRTs. The most challenging issue for the approximate Wald F test is the estimation of the denominator degrees of freedom (DDF). Some DDF approximation methods have been proposed, but their small sample performances in analysing binary outcomes in CRTs with few heterogeneous clusters are not well studied.

Methods
The small sample performances of five DDF approximations for the F test are compared and contrasted under CRT frameworks with simulations. Specifically, we illustrate how the intraclass correlation (ICC), sample size, and the variation of cluster sizes affect the type I error and statistical power when different DDF approximation methods in GLMM are used to test intervention effect in CRTs with binary outcomes. The results are also illustrated using a real CRT dataset.

Results
Our simulation results suggest that the Between-Within method maintains the nominal type I error rates even when the total number of clusters is as low as 10 and is robust to the variation of the cluster sizes. The Residual and Containment methods have inflated type I error rates when the cluster number is small ({\textless}30) and the inflation becomes more severe with increased variation in cluster sizes. In contrast, the Satterthwaite and Kenward-Roger methods can provide tests with very conservative type I error rates when the total cluster number is small ({\textless}30) and the conservativeness becomes more severe as variation in cluster sizes increases. Our simulations also suggest that the Between-Within method is statistically more powerful than the Satterthwaite or Kenward-Roger method in analysing CRTs with heterogeneous cluster sizes, especially when the cluster number is small.

Conclusion
We conclude that the Between-Within denominator degrees of freedom approximation method for F tests should be recommended when the GLMM is used in analysing CRTs with binary outcomes and few heterogeneous clusters, due to its type I error properties and relatively higher power.},
	urldate = {2019-08-15},
	journal = {BMC Medical Research Methodology},
	author = {Li, Peng and Redden, David T},
	month = apr,
	year = {2015},
	pmid = {25899170},
	pmcid = {PMC4458010},
	file = {PubMed Central Full Text PDF:/Users/jnugent/Zotero/storage/6LRBQC4X/Li and Redden - 2015 - Comparing denominator degrees of freedom approxima.pdf:application/pdf}
}

@article{chawla_kenward-roger_nodate,
	title = {Kenward-{Roger} approximation for linear mixed models with missing covariates},
	abstract = {Partially observed variables are common in scientiﬁc research. Ignoring the subjects with partial information may lead to a biased and or ineﬃcient estimators, and consequently any test based only on the completely observed subjects may inﬂate the error probabilities. Missing data issue has been extensively considered in the regression model, especially in the independently identically (IID) data setup. Relatively less attention has been paid for handling missing covariate data in the linear mixed eﬀect model– a dependent data scenario. In case of complete data, Kenward-Roger’s F test is a well established method for testing of ﬁxed eﬀects in a linear mixed model. In this paper, we present a modiﬁed Kenward-Roger type test for testing ﬁxed eﬀects in a linear mixed model when the covariates are missing at random. In the proposed method, we attempt to reduce bias from three sources, the small sample bias, the bias due to missing values, and the bias due to estimation of variance components. The operating characteristics of the method is judged and compared with two existing approaches, listwise deletion and mean imputation, via simulation studies.},
	language = {en},
	author = {Chawla, Akshita and Maiti, Tapabrata and Sinha, Samiran},
	pages = {38},
	file = {Chawla et al. - Kenward-Roger approximation for linear mixed model.pdf:/Users/jnugent/Zotero/storage/7DJBVZLY/Chawla et al. - Kenward-Roger approximation for linear mixed model.pdf:application/pdf}
}

@article{kenward_small_1997,
	title = {Small {Sample} {Inference} for {Fixed} {Effects} from {Restricted} {Maximum} {Likelihood}},
	volume = {53},
	issn = {0006-341X},
	url = {http://www.jstor.org/stable/2533558},
	doi = {10.2307/2533558},
	abstract = {Restricted maximum likelihood (REML) is now well established as a method for estimating the parameters of the general Gaussian linear model with a structured covariance matrix, in particular for mixed linear models. Conventionally, estimates of precision and inference for fixed effects are based on their asymptotic distribution, which is known to be inadequate for some small-sample problems. In this paper, we present a scaled Wald statistic, together with an F approximation to its sampling distribution, that is shown to perform well in a range of small sample settings. The statistic uses an adjusted estimator of the covariance matrix that has reduced small sample bias. This approach has the advantage that it reproduces both the statistics and F distributions in those settings where the latter is exact, namely for Hotelling T2 type statistics and for analysis of variance F-ratios. The performance of the modified statistics is assessed through simulation studies of four different REML analyses and the methods are illustrated using three examples.},
	number = {3},
	urldate = {2019-08-15},
	journal = {Biometrics},
	author = {Kenward, Michael G. and Roger, James H.},
	year = {1997},
	pages = {983--997}
}

@article{manor_small_2004,
	title = {Small sample inference for the fixed effects in the mixed linear model},
	volume = {46},
	issn = {01679473},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S016794730300238X},
	doi = {10.1016/j.csda.2003.10.005},
	abstract = {The small sample performance of several procedures for testing a given ÿxed e ect in a mixed linear model is investigated. Using simulations, constructed on the basis of a study of growth of children with Gaucher’s disease, standard normal-theory Wald tests for both ML and REML estimates, the likelihood ratio test (LRT), a modiÿed LRT based on Bartlett correction, and a number of adjusted tests based on t and F distributions are evaluated. Methods used for determining the denominator degrees of freedom in the t and F tests include the residual degrees of freedom method, the between and within degrees of freedom, the containment method, the naive method and the Satterthwaite method. A test based on a sandwich-type estimator of the variance of the parameter estimate is evaluated as well and the e ect of mis-specifying the random-e ects distribution is considered. Results show that Type I error rates for the Wald-type test with chi-square approximation are substantially in ated, though less so with REML estimates than with ML estimates. The LRT based on ML estimates yielded Type I error rates similar to those observed for the Wald-type chi-square test with REML estimates. A substantial improvement in Type I error rates for testing on both the intercept and slope is provided by each of the three following modiÿcations: the Satterthwaite and naive methods with REML-based estimates and the Bartlett-corrected LRT.},
	language = {en},
	number = {4},
	urldate = {2019-08-15},
	journal = {Computational Statistics \& Data Analysis},
	author = {Manor, Orly and Zucker, David M},
	month = jul,
	year = {2004},
	pages = {801--817},
	file = {Manor and Zucker - 2004 - Small sample inference for the fixed effects in th.pdf:/Users/jnugent/Zotero/storage/KD93EVNM/Manor and Zucker - 2004 - Small sample inference for the fixed effects in th.pdf:application/pdf}
}

@article{halekoh_kenward-roger_2014,
	title = {A {Kenward}-{Roger} {Approximation} and {Parametric} {Bootstrap} {Methods} for {Tests} in {Linear} {Mixed} {Models}  {The} {R} {Package} pbkrtest},
	volume = {59},
	copyright = {Copyright (c) 2012 Ulrich Halekoh, Søren  Højsgaard},
	issn = {1548-7660},
	url = {https://www.jstatsoft.org/index.php/jss/article/view/v059i09},
	doi = {10.18637/jss.v059.i09},
	language = {en},
	number = {1},
	urldate = {2019-08-26},
	journal = {Journal of Statistical Software},
	author = {Halekoh, Ulrich and Højsgaard, Søren},
	month = sep,
	year = {2014},
	pages = {1--32},
	file = {Full Text:/Users/jnugent/Zotero/storage/7MJ7XTDP/Halekoh and Højsgaard - 2014 - A Kenward-Roger Approximation and Parametric Boots.pdf:application/pdf;Snapshot:/Users/jnugent/Zotero/storage/MJPEVAVC/v059i09.html:text/html}
}

@article{bates_fitting_2015,
	title = {Fitting {Linear} {Mixed}-{Effects} {Models} {Using} lme4},
	volume = {67},
	copyright = {Copyright (c) 2015 Douglas Bates, Martin Mächler, Ben Bolker, Steve Walker},
	issn = {1548-7660},
	url = {https://www.jstatsoft.org/index.php/jss/article/view/v067i01},
	doi = {10.18637/jss.v067.i01},
	language = {en},
	number = {1},
	urldate = {2019-08-26},
	journal = {Journal of Statistical Software},
	author = {Bates, Douglas and Mächler, Martin and Bolker, Ben and Walker, Steve},
	month = oct,
	year = {2015},
	keywords = {Cholesky decomposition, linear mixed models, penalized least squares, sparse matrix methods},
	pages = {1--48},
	file = {Full Text:/Users/jnugent/Zotero/storage/8AVBS7HW/Bates et al. - 2015 - Fitting Linear Mixed-Effects Models Using lme4.pdf:application/pdf;Snapshot:/Users/jnugent/Zotero/storage/B3KVUZSH/v067i01.html:text/html}
}

@article{leeper_comparison_1992,
	title = {Comparison of general multivariate and random-effects models for growth curve analysis: incomplete-data smallsample situations},
	volume = {44},
	issn = {0094-9655},
	shorttitle = {Comparison of general multivariate and random-effects models for growth curve analysis},
	url = {https://doi.org/10.1080/00949659208811451},
	doi = {10.1080/00949659208811451},
	abstract = {This study investigates the application of general multivariate and the random-effects models under incomplete-data small-sample growth curve situations. The primary interest is testing hypotheses of parallelism and identity of linear growth curves for subjects in two groups. The null distributions of Wald statistics for the random-effects model are examined for appropriateness of asymptotic chi-square and recommendations are made for controlling type I error rates. Monte Carlo techniques are used to find an approximation of the null distribution. Simulations used each combination of one of three covariance structures, one of three missing data patterns (1/5, 1/3, and 2/5 proportion missing), one of two hypotheses (parallelism and identity), and one of four nominal significance levels (.05, .025,.01, and .005). This leads to a recommendation of an approximation of the null distribution for the random-effects procedure. Monte Carlo techniques are also used to compare the power performance of the procedure with the Generalized Growth Curve Multivariate (GGCM) model. Powers of the two procedures are compared over 48 cases which are combinations of covariance structures, missing data patterns, hypotheses, significance levels, and average deviation in means between two groups. The random-effects procedure has a slightly better power performance than the GGCM procedure, especially when using low significance levels when a larger proportion of data are missing.},
	number = {1-2},
	urldate = {2019-08-26},
	journal = {Journal of Statistical Computation and Simulation},
	author = {Leeper, James D. and Chang, Suming W.},
	month = dec,
	year = {1992},
	keywords = {Expectation-maximization algorithm, Missing data, Monte Carlo, Random effects, Repeated measures},
	pages = {93--104},
	file = {Snapshot:/Users/jnugent/Zotero/storage/U3VGTTDL/00949659208811451.html:text/html}
}

@article{luke_evaluating_2017,
	title = {Evaluating significance in linear mixed-effects models in {R}},
	volume = {49},
	issn = {1554-3528},
	doi = {10.3758/s13428-016-0809-y},
	abstract = {Mixed-effects models are being used ever more frequently in the analysis of experimental data. However, in the lme4 package in R the standards for evaluating significance of fixed effects in these models (i.e., obtaining p-values) are somewhat vague. There are good reasons for this, but as researchers who are using these models are required in many cases to report p-values, some method for evaluating the significance of the model output is needed. This paper reports the results of simulations showing that the two most common methods for evaluating significance, using likelihood ratio tests and applying the z distribution to the Wald t values from the model output (t-as-z), are somewhat anti-conservative, especially for smaller sample sizes. Other methods for evaluating significance, including parametric bootstrapping and the Kenward-Roger and Satterthwaite approximations for degrees of freedom, were also evaluated. The results of these simulations suggest that Type 1 error rates are closest to .05 when models are fitted using REML and p-values are derived using the Kenward-Roger or Satterthwaite approximations, as these approximations both produced acceptable Type 1 error rates even for smaller samples.},
	language = {eng},
	number = {4},
	journal = {Behavior Research Methods},
	author = {Luke, Steven G.},
	year = {2017},
	pmid = {27620283},
	keywords = {Humans, Statistics as Topic, Linear mixed-effects models, Linear Models, lme4, p-values, Sample Size, Statistics, Type 1 error},
	pages = {1494--1502},
	file = {Full Text:/Users/jnugent/Zotero/storage/PZRF6H9D/Luke - 2017 - Evaluating significance in linear mixed-effects mo.pdf:application/pdf}
}

@article{baayen_mixed-effects_2008,
	series = {Special {Issue}: {Emerging} {Data} {Analysis}},
	title = {Mixed-effects modeling with crossed random effects for subjects and items},
	volume = {59},
	issn = {0749-596X},
	url = {http://www.sciencedirect.com/science/article/pii/S0749596X07001398},
	doi = {10.1016/j.jml.2007.12.005},
	abstract = {This paper provides an introduction to mixed-effects models for the analysis of repeated measurement data with subjects and items as crossed random effects. A worked-out example of how to use recent software for mixed-effects modeling is provided. Simulation studies illustrate the advantages offered by mixed-effects analyses compared to traditional analyses based on quasi-F tests, by-subjects analyses, combined by-subjects and by-items analyses, and random regression. Applications and possibilities across a range of domains of inquiry are discussed.},
	number = {4},
	urldate = {2019-08-27},
	journal = {Journal of Memory and Language},
	author = {Baayen, R. H. and Davidson, D. J. and Bates, D. M.},
	month = nov,
	year = {2008},
	keywords = {By-item, By-subject, Crossed random effects, Mixed-effects models, Quasi-F},
	pages = {390--412},
	file = {ScienceDirect Full Text PDF:/Users/jnugent/Zotero/storage/2NBDCKN5/Baayen et al. - 2008 - Mixed-effects modeling with crossed random effects.pdf:application/pdf;ScienceDirect Snapshot:/Users/jnugent/Zotero/storage/BDULD9X8/S0749596X07001398.html:text/html}
}

@article{barr_random_2013,
	title = {Random effects structure for confirmatory hypothesis testing: {Keep} it maximal},
	volume = {68},
	issn = {0749-596X},
	shorttitle = {Random effects structure for confirmatory hypothesis testing},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3881361/},
	doi = {10.1016/j.jml.2012.11.001},
	abstract = {Linear mixed-effects models (LMEMs) have become increasingly prominent in psycholinguistics and related areas. However, many researchers do not seem to appreciate how random effects structures affect the generalizability of an analysis. Here, we argue that researchers using LMEMs for confirmatory hypothesis testing should minimally adhere to the standards that have been in place for many decades. Through theoretical arguments and Monte Carlo simulation, we show that LMEMs generalize best when they include the maximal random effects structure justified by the design. The generalization performance of LMEMs including data-driven random effects structures strongly depends upon modeling criteria and sample size, yielding reasonable results on moderately-sized samples when conservative criteria are used, but with little or no power advantage over maximal models. Finally, random-intercepts-only LMEMs used on within-subjects and/or within-items data from populations where subjects and/or items vary in their sensitivity to experimental manipulations always generalize worse than separate F1 and F2 tests, and in many cases, even worse than F1 alone. Maximal LMEMs should be the ‘gold standard’ for confirmatory hypothesis testing in psycholinguistics and beyond.},
	number = {3},
	urldate = {2019-08-27},
	journal = {Journal of memory and language},
	author = {Barr, Dale J. and Levy, Roger and Scheepers, Christoph and Tily, Harry J.},
	month = apr,
	year = {2013},
	pmid = {24403724},
	pmcid = {PMC3881361},
	file = {PubMed Central Full Text PDF:/Users/jnugent/Zotero/storage/E87L8CPK/Barr et al. - 2013 - Random effects structure for confirmatory hypothes.pdf:application/pdf}
}

@article{berkhof_variance_2001,
	title = {Variance {Component} {Testing} in {Multilevel} {Models}},
	volume = {26},
	issn = {1076-9986},
	url = {https://doi.org/10.3102/10769986026002133},
	doi = {10.3102/10769986026002133},
	abstract = {Available variance component tests are reviewed and three new score tests are presented. In the first score test, the asymptotic normal distribution of the test statistic is used as a reference distribution. In the other two score tests, a Satterthwaite approximation is used for the null distribution of the test statistic. We evaluate the performance of the score tests and other available tests by means of a Monte Carlo study. The new tests are computationally relatively cheap and have good power properties.},
	language = {en},
	number = {2},
	urldate = {2019-08-27},
	journal = {Journal of Educational and Behavioral Statistics},
	author = {Berkhof, Johannes and Snijders, Tom A. B.},
	month = jun,
	year = {2001},
	pages = {133--152},
	file = {SAGE PDF Full Text:/Users/jnugent/Zotero/storage/HBV3YIQ4/Berkhof and Snijders - 2001 - Variance Component Testing in Multilevel Models.pdf:application/pdf}
}

@article{elston_estimation_1998,
	title = {Estimation of {Denominator} {Degrees} of {Freedom} of {F}-{Distributions} for {Assessing} {Wald} {Statistics} for {Fixed}-{Effect} {Factors} in {Unbalanced} {Mixed} {Models}},
	volume = {54},
	issn = {0006-341X},
	url = {http://www.jstor.org/stable/2533859},
	doi = {10.2307/2533859},
	abstract = {Tests for fixed-effect factors in unbalanced mixed models have previously used t-tests on a contrast-by-contrast basis or Wald statistics without a universally accepted method of calculating the denominator degrees of freedom. This situation has arisen because the variances of different contrasts are differently weighted sums of the variance components with associated degrees of freedom that are not necessarily equal. A simultaneous F-test for differences between all levels of a fixed-effect factor can be derived by forming new contrasts, by rotation of the original contrasts, with variances that are close to being the same weighted sum of variance components. The associated degrees of freedom for these new contrasts are nearly equal. A small simulation study shows the appropriateness of a X2 approximation to the distribution of the weighted sums of variance components. Three simple examples are used to demonstrate the effects of rotation. The last of these examples is also used to compare the proposed simultaneous F-test with the distribution of the Wald statistic obtained by numerical simulation. The method of rotations is then applied to data on the range size of mountain hares (Lepus timidus) to assess the evidence for a two-way interaction between season and habitat.},
	number = {3},
	urldate = {2019-08-27},
	journal = {Biometrics},
	author = {Elston, D. A.},
	year = {1998},
	pages = {1085--1096},
	file = {JSTOR Full Text PDF:/Users/jnugent/Zotero/storage/8LM3CIFR/Elston - 1998 - Estimation of Denominator Degrees of Freedom of F-.pdf:application/pdf}
}

@article{welham_likelihood_1997,
	title = {Likelihood {Ratio} {Tests} for {Fixed} {Model} {Terms} using {Residual} {Maximum} {Likelihood}},
	volume = {59},
	copyright = {1997 Royal Statistical Society},
	issn = {1467-9868},
	url = {http://rss.onlinelibrary.wiley.com/doi/abs/10.1111/1467-9868.00092},
	doi = {10.1111/1467-9868.00092},
	abstract = {Likelihood ratio tests for fixed model terms are proposed for the analysis of linear mixed models when using residual maximum likelihood estimation. Bartlett-type adjustments, using an approximate decomposition of the data, are developed for the test statistics. A simulation study is used to compare properties of the test statistics proposed, with or without adjustment, with a Wald test. A proposed test statistic constructed by dropping fixed terms from the full fixed model is shown to give a better approximation to the asymptotic χ2-distribution than the Wald test for small data sets. Bartlett adjustment is shown to improve the χ2-approximation for the proposed tests substantially.},
	language = {en},
	number = {3},
	urldate = {2019-08-27},
	journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	author = {Welham, S. J. and Thompson, R.},
	year = {1997},
	keywords = {Adjusted profile likelihood, Bartlett adjustment, Likelihood ratio test, Residual maximum likelihood, Restricted maximum likelihood},
	pages = {701--714},
	file = {Full Text PDF:/Users/jnugent/Zotero/storage/A7B8Q8JA/Welham and Thompson - 1997 - Likelihood Ratio Tests for Fixed Model Terms using.pdf:application/pdf;Snapshot:/Users/jnugent/Zotero/storage/AGS25Y6I/1467-9868.html:text/html}
}

@article{wilks_large-sample_1938,
	title = {The {Large}-{Sample} {Distribution} of the {Likelihood} {Ratio} for {Testing} {Composite} {Hypotheses}},
	volume = {9},
	issn = {0003-4851},
	url = {http://www.jstor.org/stable/2957648},
	number = {1},
	urldate = {2019-09-03},
	journal = {The Annals of Mathematical Statistics},
	author = {Wilks, S. S.},
	year = {1938},
	pages = {60--62}
}

@article{yasui_evaluation_2004,
	title = {Evaluation of {Community}‐{Intervention} {Trials} via {Generalized} {Linear} {Mixed} {Models}},
	volume = {60},
	issn = {1541-0420},
	url = {http://onlinelibrary.wiley.com/doi/10.1111/j.0006-341X.2004.00260.x},
	doi = {10.1111/j.0006-341X.2004.00260.x},
	abstract = {Summary In community‐intervention trials, communities, rather than individuals, are randomized to experimental arms. Generalized linear mixed models offer a flexible parametric framework for the eval...},
	language = {en},
	number = {4},
	urldate = {2019-09-08},
	journal = {Biometrics},
	author = {Yasui, Yutaka and Feng, Ziding and Diehr, Paula and McLerran, Dale and Beresford, Shirley A. A. and McCulloch, Charles E.},
	month = dec,
	year = {2004},
	pages = {1043--1052},
	file = {Snapshot:/Users/jnugent/Zotero/storage/SQ5XKUZ3/j.0006-341X.2004.00260.html:text/html}
}

@article{catellier_tests_2000,
	title = {Tests for {Gaussian} repeated measures with missing data in small samples},
	volume = {19},
	issn = {1097-0258},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/(SICI)1097-0258(20000430)19:8<1101::AID-SIM415>3.0.CO;2-H},
	doi = {10.1002/(SICI)1097-0258(20000430)19:8<1101::AID-SIM415>3.0.CO;2-H},
	abstract = {For small samples of Gaussian repeated measures with missing data, Barton and Cramer recommended using the EM algorithm for estimation and reducing the degrees of freedom for an analogue of Rao's F a...},
	language = {en},
	number = {8},
	urldate = {2019-09-09},
	journal = {Statistics in Medicine},
	author = {Catellier, Diane J. and Muller, Keith E.},
	month = apr,
	year = {2000},
	pages = {1101--1114},
	file = {Snapshot:/Users/jnugent/Zotero/storage/F7HWHVAC/(SICI)1097-0258(20000430)1981101AID-SIM4153.0.html:text/html}
}

@article{liang_longitudinal_1986,
	title = {Longitudinal {Data} {Analysis} {Using} {Generalized} {Linear} {Models}},
	volume = {73},
	issn = {0006-3444},
	url = {http://www.jstor.org/stable/2336267},
	doi = {10.2307/2336267},
	abstract = {This paper proposes an extension of generalized linear models to the analysis of longitudinal data. We introduce a class of estimating equations that give consistent estimates of the regression parameters and of their variance under mild assumptions about the time dependence. The estimating equations are derived without specifying the joint distribution of a subject's observations yet they reduce to the score equations for multivariate Gaussian outcomes. Asymptotic theory is presented for the general class of estimators. Specific cases in which we assume independence, m-dependence and exchangeable correlation structures from each subject are discussed. Efficiency of the proposed estimators in two simple situations is considered. The approach is closely related to quasi-likelihood.},
	number = {1},
	urldate = {2019-09-10},
	journal = {Biometrika},
	author = {Liang, Kung-Yee and Zeger, Scott L.},
	year = {1986},
	pages = {13--22},
	file = {Full Text:/Users/jnugent/Zotero/storage/WCUC95UF/Liang and Zeger - 1986 - Longitudinal Data Analysis Using Generalized Linea.pdf:application/pdf}
}

@article{laird_random-effects_1982,
	title = {Random-effects models for longitudinal data},
	volume = {38},
	issn = {0006-341X},
	abstract = {Models for the analysis of longitudinal data must recognize the relationship between serial observations on the same unit. Multivariate models with general covariance structure are often difficult to apply to highly unbalanced data, whereas two-stage random-effects models can be used easily. In two-stage models, the probability distributions for the response vectors of different individuals belong to a single family, but some random-effects parameters vary across individuals, with a distribution specified at the second stage. A general family of models is discussed, which includes both growth models and repeated-measures models as special cases. A unified approach to fitting these models, based on a combination of empirical Bayes and maximum likelihood estimation of model parameters and using the EM algorithm, is discussed. Two examples are taken from a current epidemiological study of the health effects of air pollution.},
	language = {eng},
	number = {4},
	journal = {Biometrics},
	author = {Laird, N. M. and Ware, J. H.},
	month = dec,
	year = {1982},
	pmid = {7168798},
	keywords = {Humans, Statistics as Topic, Female, Male, Air Pollution, Body Height, Child, Forced Expiratory Flow Rates, Longitudinal Studies, Models, Theoretical},
	pages = {963--974}
}

@book{pinheiro_mixed-effects_2009,
	address = {New York},
	edition = {2000 edition},
	title = {Mixed-{Effects} {Models} in {S} and {S}-{PLUS}},
	isbn = {978-1-4419-0317-4},
	abstract = {An overview of the theory and application of linear and nonlinear mixed-effects models in the analysis of grouped data, such as longitudinal data, repeated measures, and multilevel data. The authors present a unified model-building strategy for both models and apply this to the analysis of over 20 real datasets from a wide variety of areas, including pharmacokinetics, agriculture, and manufacturing. Much emphasis is placed on the use of graphical displays at the various phases of the model-building process, starting with exploratory plots of the data and concluding with diagnostic plots to assess the adequacy of a fitted model. The NLME library for analyzing mixed-effects models in S and S-PLUS, developed by the authors, provides the underlying software for implementing the methods presented. This balanced mix of real data examples, modeling software, and theory makes the book a useful reference for practitioners who use, or intend to use, mixed-effects models in their data analyses. It can also be used as a text for a one-semester graduate-level applied course.},
	language = {English},
	publisher = {Springer},
	author = {Pinheiro, José and Bates, Douglas},
	month = apr,
	year = {2009}
}

@article{zucker_improved_2000,
	title = {Improved small sample inference in the mixed linear model: {Bartlett} correction and adjusted likelihood},
	volume = {62},
	copyright = {2000 Royal Statistical Society},
	issn = {1467-9868},
	shorttitle = {Improved small sample inference in the mixed linear model},
	url = {http://rss.onlinelibrary.wiley.com/doi/abs/10.1111/1467-9868.00267},
	doi = {10.1111/1467-9868.00267},
	abstract = {The mixed linear model is a popular method for analysing unbalanced repeated measurement data. The classical statistical tests for parameters in this model are based on asymptotic theory that is unreliable in the small samples that are often encountered in practice. For testing a given fixed effect parameter with a small sample, we develop and investigate refined likelihood ratio (LR) tests. The refinements considered are the Bartlett correction and use of the Cox–Reid adjusted likelihood; these are examined separately and in combination. We illustrate the various LR tests on an actual data set and compare them in two simulation studies. The conventional LR test yields type I error rates that are higher than nominal. The adjusted LR test yields rates that are lower than nominal, with absolute accuracy similar to that of the conventional LR test in the first simulation study and better in the second. The Bartlett correction substantially improves the accuracy of the type I error rates with either the conventional or the adjusted LR test. In many cases, error rates that are very close to nominal are achieved with the refined methods.},
	language = {en},
	number = {4},
	urldate = {2019-09-11},
	journal = {Journal of the Royal Statistical Society: Series B (Statistical Methodology)},
	author = {Zucker, David M. and Lieberman, Offer and Manor, Orly},
	year = {2000},
	keywords = {Higher order asymptotics, Repeated measurements},
	pages = {827--838},
	file = {Snapshot:/Users/jnugent/Zotero/storage/4R6EZP5C/1467-9868.html:text/html}
}

@article{dedrick_multilevel_2009,
	title = {Multilevel modeling: {A} review of methodological issues and applications},
	volume = {79},
	issn = {1935-1046(Electronic),0034-6543(Print)},
	shorttitle = {Multilevel modeling},
	doi = {10.3102/0034654308325581},
	abstract = {This study analyzed the reporting of multilevel modeling applications of a sample of 99 articles from 13 peer-reviewed journals in education and the social sciences. A checklist, derived from the methodological literature on multilevel modeling and focusing on the issues of model development and specification, data considerations, estimation, and inference, was used to analyze the articles. The most common applications were two-level models where individuals were nested within contexts. Most studies were non-experimental and used nonprobability samples. The amount of data at each level varied widely across studies, as did the number of models examined. Analyses of reporting practices indicated some clear problems, with many articles not reporting enough information for a reader to critique the reported analyses. For example, in many articles, one could not determine how many models were estimated, what covariance structure was assumed, what type of centering if any was used, whether the data were consistent with assumptions, whether outliers were present, or how the models were estimated. Guidelines for researchers reporting multilevel analyses are provided. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {1},
	journal = {Review of Educational Research},
	author = {Dedrick, Robert F. and Ferron, John M. and Hess, Melinda R. and Hogarty, Kristine Y. and Kromrey, Jeffrey D. and Lang, Thomas R. and Niles, John D. and Lee, Reginald S.},
	year = {2009},
	keywords = {Statistics, Education, Methodology, Scientific Communication, Simulation, Social Sciences, Statistical Analysis, Statistical Data},
	pages = {69--102},
	file = {Snapshot:/Users/jnugent/Zotero/storage/QBKLT8JW/2010-06906-003.html:text/html}
}

@article{noma_confidence_2011,
	title = {Confidence intervals for a random‐effects meta‐analysis based on {Bartlett}‐type corrections},
	volume = {30},
	issn = {1097-0258},
	url = {http://onlinelibrary.wiley.com/doi/10.1002/sim.4350},
	doi = {10.1002/sim.4350},
	abstract = {In medical meta‐analysis, the DerSimonian‐Laird confidence interval for the average treatment effect has been widely adopted in practice. However, it is well known that its coverage probability (the ...},
	language = {en},
	number = {28},
	urldate = {2019-09-11},
	journal = {Statistics in Medicine},
	author = {Noma, Hisashi},
	month = dec,
	year = {2011},
	pages = {3304--3312},
	file = {Snapshot:/Users/jnugent/Zotero/storage/PVKGYYWT/sim.html:text/html;Submitted Version:/Users/jnugent/Zotero/storage/Q7L2PCMN/Noma - 2011 - Confidence intervals for a random‐effects meta‐ana.pdf:application/pdf}
}

@article{vargas_improved_2014,
	title = {Improved likelihood inference in generalized linear models},
	volume = {74},
	issn = {0167-9473},
	url = {http://www.sciencedirect.com/science/article/pii/S0167947313004714},
	doi = {10.1016/j.csda.2013.12.002},
	abstract = {We address the issue of performing testing inference in generalized linear models when the sample size is small. This class of models provides a straightforward way of modeling normal and non-normal data and has been widely used in several practical situations. The likelihood ratio, Wald and score statistics, and the recently proposed gradient statistic provide the basis for testing inference on the parameters in these models. We focus on the small-sample case, where the reference chi-squared distribution gives a poor approximation to the true null distribution of these test statistics. We derive a general Bartlett-type correction factor in matrix notation for the gradient test which reduces the size distortion of the test, and numerically compare the proposed test with the usual likelihood ratio, Wald, score and gradient tests, and with the Bartlett-corrected likelihood ratio and score tests, and bootstrap-corrected tests. Our simulation results suggest that the corrected test we propose can be an interesting alternative to the other tests since it leads to very accurate inference even for very small samples. We also present an empirical application for illustrative purposes.11Supplementary Material presents derivation of Bartlett-type corrections to the gradient tests, and the computer code used in Section  6 (Appendix A).},
	urldate = {2019-09-11},
	journal = {Computational Statistics \& Data Analysis},
	author = {Vargas, Tiago M. and Ferrari, Silvia L. P. and Lemonte, Artur J.},
	month = jun,
	year = {2014},
	keywords = {Bartlett correction, Bartlett-type correction, Bootstrap, Generalized linear models, Gradient statistic, Likelihood ratio statistic, Score statistic, Wald statistic},
	pages = {110--124},
	file = {ScienceDirect Full Text PDF:/Users/jnugent/Zotero/storage/6LS3V5ET/Vargas et al. - 2014 - Improved likelihood inference in generalized linea.pdf:application/pdf;ScienceDirect Snapshot:/Users/jnugent/Zotero/storage/EU88VW8T/S0167947313004714.html:text/html}
}

@article{melo_improved_2009,
	title = {Improved testing inference in mixed linear models},
	volume = {53},
	issn = {0167-9473},
	url = {http://www.sciencedirect.com/science/article/pii/S0167947308005756},
	doi = {10.1016/j.csda.2008.12.007},
	abstract = {Mixed linear models are commonly used in repeated measures studies. They account for the dependence amongst observations obtained from the same experimental unit. Often, the number of observations is small, and it is thus important to use inference strategies that incorporate small sample corrections. In this paper, we develop modified versions of the likelihood ratio test for fixed effects inference in mixed linear models. In particular, we derive a Bartlett correction to such a test, and also to a test obtained from a modified profile likelihood function. Our results generalize those in [Zucker, D.M., Lieberman, O., Manor, O., 2000. Improved small sample inference in the mixed linear model: Bartlett correction and adjusted likelihood. Journal of the Royal Statistical Society B, 62, 827–838] by allowing the parameter of interest to be vector-valued. Additionally, our Bartlett corrections allow for random effects nonlinear covariance matrix structure. We report simulation results which show that the proposed tests display superior finite sample behavior relative to the standard likelihood ratio test. An application is also presented and discussed.},
	number = {7},
	urldate = {2019-09-11},
	journal = {Computational Statistics \& Data Analysis},
	author = {Melo, Tatiane F. N. and Ferrari, Silvia L. P. and Cribari-Neto, Francisco},
	month = may,
	year = {2009},
	pages = {2573--2582},
	file = {ScienceDirect Full Text PDF:/Users/jnugent/Zotero/storage/BVP9MWXI/Melo et al. - 2009 - Improved testing inference in mixed linear models.pdf:application/pdf;ScienceDirect Snapshot:/Users/jnugent/Zotero/storage/HD2GL5W9/S0167947308005756.html:text/html}
}

@article{stein_alternatives_2014,
	title = {Alternatives to the usual likelihood ratio test in mixed linear models},
	volume = {69},
	issn = {0167-9473},
	url = {http://www.sciencedirect.com/science/article/pii/S0167947313002880},
	doi = {10.1016/j.csda.2013.08.002},
	abstract = {The small-sample performance of alternatives to the usual likelihood ratio test in mixed linear models is investigated. Specifically, the following tests for fixed effects are considered: (i) a bootstrap-based test, (ii) the Bartlett-corrected usual test, and (iii) an adjusted profile likelihood ratio test. The last test is derived using an approximation to the modified profile likelihood proposed by Barndorff-Nielsen, based on the work of Severini. Bootstrap resampling is performed to numerically construct a Bartlett correction factor for the usual test statistic, and also to obtain a critical value that does not rely on first-order asymptotics. The numerical evidence presented in the paper slightly favors the Bartlett-corrected usual test. An application to real longitudinal data is presented.},
	urldate = {2019-09-11},
	journal = {Computational Statistics \& Data Analysis},
	author = {Stein, Markus Chagas and da Silva, Michel Ferreira and Duczmal, Luiz Henrique},
	month = jan,
	year = {2014},
	keywords = {Adjusted profile likelihood, Likelihood ratio test, Bartlett correction, Bootstrap, Mixed linear model},
	pages = {184--197},
	file = {ScienceDirect Full Text PDF:/Users/jnugent/Zotero/storage/ZA4RFSXB/Stein et al. - 2014 - Alternatives to the usual likelihood ratio test in.pdf:application/pdf;ScienceDirect Snapshot:/Users/jnugent/Zotero/storage/ZKUPQG6W/S0167947313002880.html:text/html}
}

@article{browne_comparison_2006,
	title = {A comparison of {Bayesian} and likelihood-based methods for fitting multilevel models},
	volume = {1},
	issn = {1936-0975, 1931-6690},
	url = {https://projecteuclid.org/euclid.ba/1340371047},
	doi = {10.1214/06-BA117},
	abstract = {We use simulation studies, whose design is realistic for educational and medical research (as well as other fields of inquiry), to compare Bayesian and likelihood-based methods for fitting variance-components (VC) and random-effects logistic regression (RELR) models. The likelihood (and approximate likelihood) approaches we examine are based on the methods most widely used in current applied multilevel (hierarchical) analyses: maximum likelihood (ML) and restricted ML (REML) for Gaussian outcomes, and marginal and penalized quasi-likelihood (MQL and PQL) for Bernoulli outcomes. Our Bayesian methods use Markov chain Monte Carlo (MCMC) estimation, with adaptive hybrid Metropolis-Gibbs sampling for RELR models, and several diffuse prior distributions (Γ−1(ϵ,ϵ)Γ−1(ϵ,ϵ){\textbackslash}Gamma{\textasciicircum}\{ -1 \}( {\textbackslash}epsilon, {\textbackslash}epsilon ) and U(0,1ϵ)U(0,1ϵ)U( 0, {\textbackslash}frac\{ 1 \}\{ {\textbackslash}epsilon \} ) priors for variance components). For evaluation criteria we consider bias of point estimates and nominal versus actual coverage of interval estimates in repeated sampling. In two-level VC models we find that (a) both likelihood-based and Bayesian approaches can be made to produce approximately unbiased estimates, although the automatic manner in which REML accomplishes this is an advantage, but (b) both approaches had difficulty achieving nominal coverage in small samples and with small values of the intraclass correlation. With the three-level RELR models we examine we find that (c) quasi-likelihood methods for estimating random-effects variances perform badly with respect to bias and coverage in the example we simulated, and (d) Bayesian diffuse-prior methods lead to well-calibrated point and interval RELR estimates. While it is true that the likelihood-based methods we study are considerably faster computationally than MCMC, (i) steady improvements in recent years in both hardware speed and efficiency of Monte Carlo algorithms and (ii) the lack of calibration of likelihood-based methods in some common hierarchical settings combine to make MCMC-based Bayesian fitting of multilevel models an attractive approach, even with rather large data sets. Other analytic strategies based on less approximate likelihood methods are also possible but would benefit from further study of the type summarized here.},
	language = {EN},
	number = {3},
	urldate = {2019-09-15},
	journal = {Bayesian Analysis},
	author = {Browne, William J. and Draper, David},
	month = sep,
	year = {2006},
	mrnumber = {MR2221283},
	zmnumber = {1331.62125},
	keywords = {Adaptive MCMC, bias, calibration, diffuse priors, hierarchical modeling, hybrid Metropolis-Gibbs sampling, IGLS, interval coverage, intraclass correlation, mixed models, MQL, PQL, random-effects logistic regression, REML, RIGLS, variance-components models},
	pages = {473--514},
	file = {Full Text PDF:/Users/jnugent/Zotero/storage/S4NP6C89/Browne and Draper - 2006 - A comparison of Bayesian and likelihood-based meth.pdf:application/pdf;Snapshot:/Users/jnugent/Zotero/storage/TDY9I4RC/1340371047.html:text/html}
}

@incollection{feng_small_2004,
	address = {New York, NY},
	series = {Lecture {Notes} in {Statistics}},
	title = {Small {Sample} {Inference} for {Clustered} {Data}},
	isbn = {978-1-4419-9076-1},
	url = {https://doi.org/10.1007/978-1-4419-9076-1_5},
	abstract = {When the number of independent units is not adequate to invoke large sample approximations in clustered data analysis, a situation that often arises in group randomized trials (GRTs), valid and efficient small sample inference becomes important. We review the current methods for analyzing data from small numbers of clusters, namely methods based on full distribution assumptions (mixed effect models), semi-parametric methods based on Generalized Estimating Equations (GEE), and non-parametric methods based on permutation tests.},
	language = {en},
	urldate = {2019-09-15},
	booktitle = {Proceedings of the {Second} {Seattle} {Symposium} in {Biostatistics}: {Analysis} of {Correlated} {Data}},
	publisher = {Springer New York},
	author = {Feng, Ziding and Braun, Thomas and McCulloch, Charles},
	editor = {Lin, D. Y. and Heagerty, P. J.},
	year = {2004},
	doi = {10.1007/978-1-4419-9076-1_5},
	keywords = {linear mixed models, Correlated data, Generalized Estimating Equations (GEE), group randomized trials, permutation tests, small sample inference},
	pages = {71--87}
}

@article{clarke_addressing_2007,
	title = {Addressing {Data} {Sparseness} in {Contextual} {Population} {Research}: {Using} {Cluster} {Analysis} to {Create} {Synthetic} {Neighborhoods}},
	volume = {35},
	issn = {0049-1241},
	shorttitle = {Addressing {Data} {Sparseness} in {Contextual} {Population} {Research}},
	url = {https://doi.org/10.1177/0049124106292362},
	doi = {10.1177/0049124106292362},
	abstract = {The use of multilevel modeling with data from population-based surveys is often limited by the small number of cases per Level 2 unit, prompting a recent trend in the neighborhood literature to apply cluster techniques to address the problem of data sparseness. In this study, the authors use Monte Carlo simulations to investigate the effects of marginal group sizes on multilevel model performance, bias, and efficiency. They then employ cluster analysis techniques to minimize data sparseness and examine the consequences in the simulations. They find that estimates of the fixed effects are robust at the extremes of data sparseness, while cluster analysis is an effective strategy to increase group size and prevent the overestimation of variance components. However, researchers should be cautious about the degree to which they use such clustering techniques due to the introduction of artificial within-group heterogeneity.},
	language = {en},
	number = {3},
	urldate = {2019-09-15},
	journal = {Sociological Methods \& Research},
	author = {Clarke, Philippa and Wheaton, Blair},
	month = feb,
	year = {2007},
	pages = {311--351},
	file = {SAGE PDF Full Text:/Users/jnugent/Zotero/storage/AVIL8TLU/Clarke and Wheaton - 2007 - Addressing Data Sparseness in Contextual Populatio.pdf:application/pdf}
}

@article{schluchter_small-sample_1990,
	title = {Small-sample adjustments to tests with unbalanced repeated measures assuming several covariance structures},
	volume = {37},
	issn = {0094-9655},
	url = {https://doi.org/10.1080/00949659008811295},
	doi = {10.1080/00949659008811295},
	abstract = {Recent advances in methods for analysis of longitudinal data arid incomplete repeated measures have been in the area of maximum likelihood (ML) and restricted maximum likelihood (REML) methods (e.g., Laird and Ware, 1982 Biometrics, Jennrich and Schluchter, 1986 Biometrics). This paper outlines the ML and REML approaches to the analysis of incomplete repeated measures data and growth curves, and then examines methods for small-sample adjustment of asymptotic Wald-type chi-square tests constructed from ML and REML estimates under four different assumed covariance structures. These adjustments involve transformation of the Wald Ghi-square statistic to an approximate F-statistic. In certain cases when data are complete and balanced, the transformed test statistics have exact F-distribution under the null hypothesis. The first three covariance structures: (1) Compound Symmetry, (2) First-Order Autoregressive, and (3) Multivariate (unstructured), are examined in the context of the analysis of a repeated measures d sign having a single between-subjects factor and a single within-subjects factor. The fourth model, which implies a special type of covariance structure, is a Linear Random Effects Growth Curve Model. For each covariance structure model, we review known exact results both for the case of balanced and unbalanced data. We then examine the type I error rates of the various tests via a small simulation study. It is shown that the most appropriate type of small-sample correction depends upon the form of the assumed covariance structure, whether ML or REML procedures are used, and whether the test is a ‘between groups' or ‘within-subject' test. The results emphasize the importance of applying a correction to the asymptotic tests in small samples.},
	number = {1-2},
	urldate = {2019-09-15},
	journal = {Journal of Statistical Computation and Simulation},
	author = {Schluchter, Mark D. and Elashoff, Janet T.},
	month = oct,
	year = {1990},
	keywords = {Autoregressive models, growth curves, incomplete data, random-effects models, restricted maximum likelihood, Wald tests},
	pages = {69--87},
	file = {Snapshot:/Users/jnugent/Zotero/storage/ZQTEANNZ/00949659008811295.html:text/html}
}

@article{mcneish_small_2017,
	title = {Small {Sample} {Methods} for {Multilevel} {Modeling}: {A} {Colloquial} {Elucidation} of {REML} and the {Kenward}-{Roger} {Correction}},
	volume = {52},
	issn = {0027-3171},
	shorttitle = {Small {Sample} {Methods} for {Multilevel} {Modeling}},
	url = {https://doi.org/10.1080/00273171.2017.1344538},
	doi = {10.1080/00273171.2017.1344538},
	abstract = {Studies on small sample properties of multilevel models have become increasingly prominent in the methodological literature in response to the frequency with which small sample data appear in empirical studies. Simulation results generally recommend that empirical researchers employ restricted maximum likelihood estimation (REML) with a Kenward-Roger correction with small samples in frequentist contexts to minimize small sample bias in estimation and to prevent inflation of Type-I error rates. However, simulation studies focus on recommendations for best practice, and there is little to no explanation of why traditional maximum likelihood (ML) breaks down with smaller samples, what differentiates REML from ML, or how the Kenward-Roger correction remedies lingering small sample issues. Due to the complexity of these methods, most extant descriptions are highly mathematical and are intended to prove that the methods improve small sample performance as intended. Thus, empirical researchers have documentation that these methods are advantageous but still lack resources to help understand what the methods actually do and why they are needed. This tutorial explains why ML falters with small samples, how REML circumvents some issues, and how Kenward-Roger works. We do so without equations or derivations to support more widespread understanding and use of these valuable methods.},
	number = {5},
	urldate = {2019-09-15},
	journal = {Multivariate Behavioral Research},
	author = {McNeish, Daniel},
	month = sep,
	year = {2017},
	pmid = {28715244},
	keywords = {Restricted maximum likelihood, explanation, Kenward-Roger, mixed model, tutorial},
	pages = {661--670},
	file = {Full Text PDF:/Users/jnugent/Zotero/storage/YL2R7NYD/McNeish - 2017 - Small Sample Methods for Multilevel Modeling A Co.pdf:application/pdf;Snapshot:/Users/jnugent/Zotero/storage/3QTQG3C2/00273171.2017.html:text/html}
}

@article{mcneish_effect_2016,
	title = {The {Effect} of {Small} {Sample} {Size} on {Two} {Level} {Model} {Estimates}: {A} {Review} and {Illustration}},
	volume = {28},
	shorttitle = {The {Effect} of {Small} {Sample} {Size} on {Two} {Level} {Model} {Estimates}},
	doi = {10.1007/s10648-014-9287-x},
	abstract = {Multilevel models are an increasingly popular method to analyze data that originate from a clustered or hierarchical structure. To effectively utilize multilevel models, one must have an adequately large number of clusters; otherwise, some model parameters will be estimated with bias. The goals for this paper are to (1) raise awareness of the problems associated with a small number of clusters, (2) review previous studies on multilevel models with a small number of clusters, (3) to provide an illustrative simulation to demonstrate how a simple model becomes adversely affected by small numbers of clusters, (4) to provide researchers with remedies if they encounter clustered data with a small number of clusters, and (5) to outline methodological topics that have yet to be addressed in the literature.},
	journal = {Educational Psychology Review},
	author = {McNeish, Daniel and Stapleton, Laura},
	month = jun,
	year = {2016},
	file = {Full Text PDF:/Users/jnugent/Zotero/storage/RLBF9ZVW/McNeish and Stapleton - 2016 - The Effect of Small Sample Size on Two Level Model.pdf:application/pdf}
}

@article{konstantopoulos_power_2010,
	title = {Power {Analysis} in {Two}-{Level} {Unbalanced} {Designs}},
	volume = {78},
	issn = {0022-0973},
	url = {https://doi.org/10.1080/00220970903292876},
	doi = {10.1080/00220970903292876},
	abstract = {Previous work on statistical power has discussed mainly single-level designs or 2-level balanced designs with random effects. Although balanced experiments are common, in practice balance cannot always be achieved. Work on class size is one example of unbalanced designs. This study provides methods for power analysis in 2-level unbalanced designs with random effects. Overall, the nesting affects power negatively, the treatment affects power positively, and the Level-2 units affect power more than Level-1 units. Computing power assuming balanced designs provides reasonable estimates only when imbalance is mild or moderate. When imbalance is large or extreme, computing power assuming balanced designs produces larger estimates of power. The use of the harmonic mean provides accurate estimates of power in unbalanced 2-level designs even when imbalance is large.},
	number = {3},
	urldate = {2019-09-15},
	journal = {The Journal of Experimental Education},
	author = {Konstantopoulos, Spyros},
	month = mar,
	year = {2010},
	keywords = {experiments, multilevel models, nested designs, random effects, statistical power, unbalanced designs},
	pages = {291--317},
	file = {Full Text PDF:/Users/jnugent/Zotero/storage/4API9P5I/Konstantopoulos - 2010 - Power Analysis in Two-Level Unbalanced Designs.pdf:application/pdf;Snapshot:/Users/jnugent/Zotero/storage/W6NZA99C/00220970903292876.html:text/html}
}

@article{scherbaum_estimating_2009,
	title = {Estimating {Statistical} {Power} and {Required} {Sample} {Sizes} for {Organizational} {Research} {Using} {Multilevel} {Modeling}},
	volume = {12},
	issn = {1094-4281},
	url = {https://doi.org/10.1177/1094428107308906},
	doi = {10.1177/1094428107308906},
	abstract = {The use of multilevel modeling to investigate organizational phenomena is rapidly increasing. Unfortunately, little advice is readily available for organizational researchers attempting to determine statistical power when using multilevel models or when determining sample sizes for each level that will maximize statistical power. This article presents an introduction to statistical power in multilevel models. The unique factors influencing power in multilevel models and calculations for estimating power for simple fixed effects, variance components, and cross-level interactions are presented. The results of simulation studies and the existing general rules of thumb are discussed, and the available power analysis software is reviewed.},
	language = {en},
	number = {2},
	urldate = {2019-09-15},
	journal = {Organizational Research Methods},
	author = {Scherbaum, Charles A. and Ferreter, Jennifer M.},
	month = apr,
	year = {2009},
	pages = {347--367},
	file = {SAGE PDF Full Text:/Users/jnugent/Zotero/storage/HT24AZCK/Scherbaum and Ferreter - 2009 - Estimating Statistical Power and Required Sample S.pdf:application/pdf}
}

@article{ferron_making_2009,
	title = {Making treatment effect inferences from multiple-baseline data: {The} utility of multilevel modeling approaches},
	volume = {41},
	issn = {1554-3528},
	shorttitle = {Making treatment effect inferences from multiple-baseline data},
	url = {https://doi.org/10.3758/BRM.41.2.372},
	doi = {10.3758/BRM.41.2.372},
	abstract = {Multiple-baseline studies are prevalent in behavioral research, but questions remain about how to best analyze the resulting data. Monte Carlo methods were used to examine the utility of multilevel models for multiplebaseline data under conditions that varied in the number of participants, number of repeated observations per participant, variance in baseline levels, variance in treatment effects, and amount of autocorrelation in the Level 1 errors. Interval estimates of the average treatment effect were examined for two specifications of the Level 1 error structure (σ2 I and first-order autoregressive) and for five different methods of estimating the degrees of freedom (containment, residual, between—within, Satterthwaite, and Kenward—Roger). When the Satterthwaite or Kenward—Roger method was used and an autoregressive Level 1 error structure was specified, the interval estimates of the average treatment effect were relatively accurate. Conversely, the interval estimates of the treatment effect variance were inaccurate, and the corresponding point estimates were biased.},
	language = {en},
	number = {2},
	urldate = {2019-09-15},
	journal = {Behavior Research Methods},
	author = {Ferron, John M. and Bell, Bethany A. and Hess, Melinda R. and Rendina-Gobioff, Gianna and Hibbard, Susan T.},
	month = may,
	year = {2009},
	keywords = {Autocorrelation, Average Treatment Effect, Error Structure, FERRON, Interval Estimate},
	pages = {372--384},
	file = {Springer Full Text PDF:/Users/jnugent/Zotero/storage/LVXFCJAX/Ferron et al. - 2009 - Making treatment effect inferences from multiple-b.pdf:application/pdf}
}

@article{baldwin_bayesian_2013,
	title = {Bayesian methods for the analysis of small sample multilevel data with a complex variance structure},
	volume = {18},
	issn = {1939-1463(Electronic),1082-989X(Print)},
	doi = {10.1037/a0030642},
	abstract = {Inferences from multilevel models can be complicated in small samples or complex data structures. When using (restricted) maximum likelihood methods to estimate multilevel models, standard errors and degrees of freedom often need to be adjusted to ensure that inferences for fixed effects are correct. These adjustments do not address problems in estimating variance/covariance components. An alternative to the adjusted likelihood method is to use Bayesian methods, which can produce accurate inferences about fixed effects and variance/covariance parameters. In this article, the authors contrast the benefits and limitations of likelihood and Bayesian methods in the estimation of multilevel models. The issues are discussed in the context of a partially clustered intervention study, a common intervention design that has been shown to require an adjusted likelihood analysis. The authors report a Monte Carlo study that compares the performance of an adjusted restricted maximum likelihood (REML) analysis to a Bayesian analysis. The results suggest that for fixed effects, the models perform equally well with respect to bias, efficiency, and coverage of interval estimates. Bayesian models with a carefully selected gamma prior for the variance components were more biased but also more efficient with respect to estimation of the variance components than the REML model. However, the results also show that the inferences about the variance components in partially clustered studies are sensitive to the prior distribution when sample sizes are small. Finally, the authors compare the results of a Bayesian and adjusted likelihood model using data from a partially clustered intervention trial. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
	number = {2},
	journal = {Psychological Methods},
	author = {Baldwin, Scott A. and Fellingham, Gilbert W.},
	year = {2013},
	keywords = {Sample Size, Estimation, Intervention, Mathematical Modeling, Maximum Likelihood, Statistical Probability},
	pages = {151--164},
	file = {Snapshot:/Users/jnugent/Zotero/storage/VPHZYKSV/2012-30274-001.html:text/html}
}

@article{bartlett_properties_1937,
	title = {Properties of sufficiency and statistical tests},
	volume = {160},
	url = {https://royalsocietypublishing.org/doi/abs/10.1098/rspa.1937.0109},
	doi = {10.1098/rspa.1937.0109},
	abstract = {1—In a previous paper, dealing with the importance of properties of sufficiency in the statistical theory of small samples, attention was mainly confined to the theory of estimation. In the present paper the structure of small sample tests, whether these are related to problems of estimation and fiducial distributions, or are of the nature of tests of goodness of fit, is considered further. The notation a {\textbar} b implies as before that the variate a is conditioned by a given value of b. The fixed variate b may be denoted by {\textbar} b, and analogously if b is clear from the context, a {\textbar} b may be written simply as a {\textbar}. Corresponding to the idea of ancillary information introduced by Fisher for the case of a single unknown θ, where auxiliary statistics control the accuracy of our estimate, I have termed a conditional statistic of the form T {\textbar}, quasi-sufficient, if its distribution satisfies the “sufficiency” property and contains all the information on θ. In the more general case of other unknowns, such a statistic may contain all the available information on θ.},
	number = {901},
	urldate = {2019-09-15},
	journal = {Proceedings of the Royal Society of London. Series A - Mathematical and Physical Sciences},
	author = {Bartlett, Maurice Stevenson and Fowler, Ralph Howard},
	month = may,
	year = {1937},
	pages = {268--282},
	file = {Full Text PDF:/Users/jnugent/Zotero/storage/NU5IHW27/Bartlett and Fowler - 1937 - Properties of sufficiency and statistical tests.pdf:application/pdf;Snapshot:/Users/jnugent/Zotero/storage/XC6AJ5NT/rspa.1937.html:text/html}
}

@book{kreft_introducing_1998,
	address = {London ; Thousand Oaks, Calif},
	edition = {1 edition},
	title = {Introducing {Multilevel} {Modeling}},
	isbn = {978-0-7619-5141-4},
	abstract = {Authors Ita G. G. Kreft and Jan de Leeuw have provided the first accessible and practical guide to using multilevel models in social research. Multilevel approaches are becoming increasingly important in social, behavioral, and educational research and it is clear from recent developments that such models are seen as more realisticùand potentially more revealingùthan ordinary regression models. While other books describe these multilevel models in considerable detail none focus on the practical issues and potential problems of doing multilevel analyses that are covered in Introducing Multilevel Modeling. The authorsÆ approach is user-oriented, keeping formal mathematics and statistics to a minimum. Other key features include the use of worked examples using real data sets, analyzed using the leading computer package for multilevel modeling.},
	language = {English},
	publisher = {SAGE Publications Ltd},
	author = {Kreft, Ita G. G.},
	month = jun,
	year = {1998}
}

@article{maas_sufficient_2005,
	title = {Sufficient {Sample} {Sizes} for {Multilevel} {Modeling}},
	volume = {1},
	issn = {1614-1881},
	url = {https://econtent.hogrefe.com/doi/10.1027/1614-2241.1.3.86},
	doi = {10.1027/1614-2241.1.3.86},
	abstract = {. An important problem in multilevel modeling is what constitutes a sufficient sample size for accurate estimation. In multilevel analysis, the major restriction is often the higher-level sample size. In this paper, a simulation study is used to determine the influence of different sample sizes at the group level on the accuracy of the estimates (regression coefficients and variances) and their standard errors. In addition, the influence of other factors, such as the lowest-level sample size and different variance distributions between the levels (different intraclass correlations), is examined. The results show that only a small sample size at level two (meaning a sample of 50 or less) leads to biased estimates of the second-level standard errors. In all of the other simulated conditions the estimates of the regression coefficients, the variance components, and the standard errors are unbiased and accurate.},
	number = {3},
	urldate = {2019-09-16},
	journal = {Methodology},
	author = {Maas, Cora J. M. and Hox, Joop J.},
	month = jan,
	year = {2005},
	pages = {86--92},
	file = {Snapshot:/Users/jnugent/Zotero/storage/NL78NRDN/1614-2241.1.3.html:text/html}
}

@article{bell_dancing_2010,
	title = {Dancing the {Sample} {Size} {Limbo} with {Mixed} {Models}: {How} {Low} {Can} {You} {Go}?},
	volume = {4},
	shorttitle = {Dancing the {Sample} {Size} {Limbo} with {Mixed} {Models}},
	abstract = {Whereas general sample size guidelines have been suggested when estimating multilevel models, they are only generalizable to a relatively limited number of data conditions and model structures, both of which are not very feasible for the applied researcher. In an effort to expand our understanding of two-level multilevel models under less than ideal conditions, Monte Carlo methods, through SAS/IML, were used to examine model convergence rates, parameter point estimates (statistical bias), parameter interval estimates (confidence interval accuracy and precision), and both Type I error control and statistical power of tests associated with the fixed effects, from linear two-level models estimated with PROC MIXED. These outcomes were analyzed as a function of: (a) level-1 sample size, (b) level-2 sample size, (c) intercept variance, (d) slope variance, (e) collinearity, and (f) model complexity.},
	journal = {SAS Global Forum},
	author = {Bell, Bethany and Morgan, Grant and Schoeneberger, Jason and Loudermilk, Louise and Kromrey, Jeffrey and Ferron, John},
	month = jan,
	year = {2010},
	file = {Full Text PDF:/Users/jnugent/Zotero/storage/QXZ5EHF3/Bell et al. - 2010 - Dancing the Sample Size Limbo with Mixed Models H.pdf:application/pdf}
}

@article{ukyo_improved_2019,
	title = {Improved {Small} {Sample} {Inference} {Methods} for a {Mixed}-{Effects} {Model} for {Repeated} {Measures} {Approach} in {Incomplete} {Longitudinal} {Data} {Analysis}},
	volume = {2},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	url = {https://www.mdpi.com/2571-905X/2/2/13},
	doi = {10.3390/stats2020013},
	abstract = {The mixed-effects model for repeated measures (MMRM) approach has been widely applied for longitudinal clinical trials. Many of the standard inference methods of MMRM could possibly lead to the inflation of type I error rates for the tests of treatment effect, when the longitudinal dataset is small and involves missing measurements. We propose two improved inference methods for the MMRM analyses, (1) the Bartlett correction with the adjustment term approximated by bootstrap, and (2) the Monte Carlo test using an estimated null distribution by bootstrap. These methods can be implemented regardless of model complexity and missing patterns via a unified computational framework. Through simulation studies, the proposed methods maintain the type I error rate properly, even for small and incomplete longitudinal clinical trial settings. Applications to a postnatal depression clinical trial are also presented.},
	language = {en},
	number = {2},
	urldate = {2019-09-17},
	journal = {Stats},
	author = {Ukyo, Yoshifumi and Noma, Hisashi and Maruo, Kazushi and Gosho, Masahiko},
	month = jun,
	year = {2019},
	keywords = {Bartlett adjustment, longitudinal data analysis, missing data, MMRM, resampling},
	pages = {174--188},
	file = {Full Text PDF:/Users/jnugent/Zotero/storage/FQXC5LYP/Ukyo et al. - 2019 - Improved Small Sample Inference Methods for a Mixe.pdf:application/pdf;Snapshot:/Users/jnugent/Zotero/storage/M2HABMEE/13.html:text/html}
}

@misc{noauthor_likelihood_nodate,
	title = {Likelihood ratio tests in linear mixed models with one variance component - {Crainiceanu} - 2004 - {Journal} of the {Royal} {Statistical} {Society}: {Series} {B} ({Statistical} {Methodology}) - {Wiley} {Online} {Library}},
	url = {https://rss-onlinelibrary-wiley-com.silk.library.umass.edu/doi/10.1111/j.1467-9868.2004.00438.x},
	urldate = {2019-10-01},
	file = {Likelihood ratio tests in linear mixed models with one variance component - Crainiceanu - 2004 - Journal of the Royal Statistical Society\: Series B (Statistical Methodology) - Wiley Online Library:/Users/jnugent/Zotero/storage/5AB7656V/j.1467-9868.2004.00438.html:text/html}
}

@article{leyrat_cluster_2018,
	title = {Cluster randomized trials with a small number of clusters: which analyses should be used?},
	volume = {47},
	issn = {1464-3685},
	shorttitle = {Cluster randomized trials with a small number of clusters},
	doi = {10.1093/ije/dyx169},
	abstract = {Background: Cluster randomized trials (CRTs) are increasingly used to assess the effectiveness of health interventions. Three main analysis approaches are: cluster-level analyses, mixed-models and generalized estimating equations (GEEs). Mixed models and GEEs can lead to inflated type I error rates with a small number of clusters, and numerous small-sample corrections have been proposed to circumvent this problem. However, the impact of these methods on power is still unclear.
Methods: We performed a simulation study to assess the performance of 12 analysis approaches for CRTs with a continuous outcome and 40 or fewer clusters. These included weighted and unweighted cluster-level analyses, mixed-effects models with different degree-of-freedom corrections, and GEEs with and without a small-sample correction. We assessed these approaches across different values of the intraclass correlation coefficient (ICC), numbers of clusters and variability in cluster sizes.
Results: Unweighted and variance-weighted cluster-level analysis, mixed models with degree-of-freedom corrections, and GEE with a small-sample correction all maintained the type I error rate at or below 5\% across most scenarios, whereas uncorrected approaches lead to inflated type I error rates. However, these analyses had low power (below 50\% in some scenarios) when fewer than 20 clusters were randomized, with none reaching the expected 80\% power.
Conclusions: Small-sample corrections or variance-weighted cluster-level analyses are recommended for the analysis of continuous outcomes in CRTs with a small number of clusters. The use of these corrections should be incorporated into the sample size calculation to prevent studies from being underpowered.},
	language = {eng},
	number = {1},
	journal = {International Journal of Epidemiology},
	author = {Leyrat, Clémence and Morgan, Katy E. and Leurent, Baptiste and Kahan, Brennan C.},
	year = {2018},
	pmid = {29025158},
	keywords = {Data Interpretation, Statistical, Humans, Models, Statistical, Randomized Controlled Trials as Topic, Sample Size, Analysis of Variance, Cluster Analysis, Computer Simulation},
	pages = {321--331},
	file = {Full Text:/Users/jnugent/Zotero/storage/IBAFFFQ8/Leyrat et al. - 2018 - Cluster randomized trials with a small number of c.pdf:application/pdf}
}

@article{giesbrecht_two-stage_1985,
	title = {Two-{Stage} {Analysis} {Based} on a {Mixed} {Model}: {Large}-{Sample} {Asymptotic} {Theory} and {Small}-{Sample} {Simulation} {Results}},
	volume = {41},
	issn = {0006-341X},
	shorttitle = {Two-{Stage} {Analysis} {Based} on a {Mixed} {Model}},
	url = {http://www.jstor.org/stable/2530872},
	doi = {10.2307/2530872},
	abstract = {A two-stage analysis for the mixed model in which variance components due to the random effects are estimated and used to compute generalized least squares estimates of fixed effects is developed. Large-sample theory is used to establish asymptotic properties. An approximate t test that can be used to test linear contrasts among fixed effects is discussed. Two modest simulations, based on a model for a grazing trial (Burns, Harvey, and Giesbrecht, 1981, Proceedings of 14th International Grassland Conference, J. A. Smith and V. W. Hays (eds), 497-500, Boulder, Colorado: Westview Press; Burns et al., 1983, Agronomy Journal 75, 865-871) are used to show that the asymptotic results are reasonable for small samples.},
	number = {2},
	urldate = {2019-10-01},
	journal = {Biometrics},
	author = {Giesbrecht, F. G. and Burns, J. C.},
	year = {1985},
	pages = {477--486}
}

@article{mclean_unified_1991,
	title = {A {Unified} {Approach} to {Mixed} {Linear} {Models}},
	volume = {45},
	issn = {0003-1305},
	url = {http://www.jstor.org/stable/2685241},
	doi = {10.2307/2685241},
	abstract = {The mixed model equations as presented by C. R. Henderson offers the base for a methodology that provides flexibility of fitting models with various fixed and random elements with the possible assumption of correlation among random effects. The advantage of teaching analysis of variance applications from this methodology is presented. Particular emphasis is placed upon the relationship between choice of estimable function and inference space.},
	number = {1},
	urldate = {2019-10-01},
	journal = {The American Statistician},
	author = {McLean, Robert A. and Sanders, William L. and Stroup, Walter W.},
	year = {1991},
	pages = {54--64}
}

@article{fai_approximate_1996,
	title = {Approximate {F}-tests of multiple degree of freedom hypotheses in generalized least squares analyses of unbalanced split-plot experiments},
	volume = {54},
	issn = {0094-9655},
	url = {https://doi.org/10.1080/00949659608811740},
	doi = {10.1080/00949659608811740},
	abstract = {Approximate t-tests of single degree of freedom hypotheses in generalized least squares analyses (GLS) of mixed linear models using restricted maximum likelihood (REML) estimates of variance components have been previously developed by Giesbrecht and Burns (GB), and by Jeske and Harville (JH), using method of moment approximations for the degrees of freedom (df) for the tstatistics. This paper proposes approximate Fstatistics for tests of multiple df hypotheses using one-moment and two-moment approximations which may be viewed as extensions of the GB and JH methods. The paper focuses specifically on tests of hypotheses concerning the main-plot treatment factor in split-plot experiments with missing data. Simulation results indicate usually satisfactory control of Type I error rates.},
	number = {4},
	urldate = {2019-10-01},
	journal = {Journal of Statistical Computation and Simulation},
	author = {Fai, Alex Hrong-Tai and Cornelius, Paul L.},
	month = jun,
	year = {1996},
	keywords = {mixed models, F-test, generalized least squares, Satterthwaite’s approximation, splitplots},
	pages = {363--378},
	file = {Snapshot:/Users/jnugent/Zotero/storage/MM63CSL9/00949659608811740.html:text/html}
}

@book{gatsonis_methods_2017,
	address = {Boca Raton},
	edition = {1 edition},
	title = {Methods in {Comparative} {Effectiveness} {Research}},
	isbn = {978-1-4665-1196-5},
	abstract = {Comparative effectiveness research (CER) is the generation and synthesis of evidence that compares the benefits and harms of alternative methods to prevent, diagnose, treat, and monitor a clinical condition or to improve the delivery of care (IOM 2009). CER is conducted to develop evidence that will aid patients, clinicians, purchasers, and health policy makers in making informed decisions at both the individual and population levels. CER encompasses a very broad range of types of studies―experimental, observational, prospective, retrospective, and research synthesis.   This volume covers the main areas of quantitative methodology for the design and analysis of CER studies. The volume has four major sections―causal inference; clinical trials; research synthesis; and specialized topics. The audience includes CER methodologists, quantitative-trained researchers interested in CER, and graduate students in statistics, epidemiology, and health services and outcomes research. The book assumes a masters-level course in regression analysis and familiarity with clinical research.},
	language = {English},
	publisher = {Chapman and Hall/CRC},
	editor = {Gatsonis, Constantine and Morton, Sally C.},
	month = feb,
	year = {2017}
}

@article{kahan_increased_2016,
	title = {Increased risk of type {I} errors in cluster randomised trials with small or medium numbers of clusters: a review, reanalysis, and simulation study},
	volume = {17},
	issn = {1745-6215},
	shorttitle = {Increased risk of type {I} errors in cluster randomised trials with small or medium numbers of clusters},
	url = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5013635/},
	doi = {10.1186/s13063-016-1571-2},
	abstract = {Background
Cluster randomised trials (CRTs) are commonly analysed using mixed-effects models or generalised estimating equations (GEEs). However, these analyses do not always perform well with the small number of clusters typical of most CRTs. They can lead to increased risk of a type I error (finding a statistically significant treatment effect when it does not exist) if appropriate corrections are not used.

Methods
We conducted a small simulation study to evaluate the impact of using small-sample corrections for mixed-effects models or GEEs in CRTs with a small number of clusters. We then reanalysed data from TRIGGER, a CRT with six clusters, to determine the effect of using an inappropriate analysis method in practice. Finally, we reviewed 100 CRTs previously identified by a search on PubMed in order to assess whether trials were using appropriate methods of analysis. Trials were classified as at risk of an increased type I error rate if they did not report using an analysis method which accounted for clustering, or if they had fewer than 40 clusters and performed an individual-level analysis without reporting the use of an appropriate small-sample correction.

Results
Our simulation study found that using mixed-effects models or GEEs without an appropriate correction led to inflated type I error rates, even for as many as 70 clusters. Conversely, using small-sample corrections provided correct type I error rates across all scenarios. Reanalysis of the TRIGGER trial found that inappropriate methods of analysis gave much smaller P values (P ≤ 0.01) than appropriate methods (P = 0.04–0.15). In our review, of the 99 trials that reported the number of clusters, 64 (65 \%) were at risk of an increased type I error rate; 14 trials did not report using an analysis method which accounted for clustering, and 50 trials with fewer than 40 clusters performed an individual-level analysis without reporting the use of an appropriate correction.

Conclusions
CRTs with a small or medium number of clusters are at risk of an inflated type I error rate unless appropriate analysis methods are used. Investigators should consider using small-sample corrections with mixed-effects models or GEEs to ensure valid results.},
	number = {1},
	urldate = {2019-10-06},
	journal = {Trials},
	author = {Kahan, Brennan C. and Forbes, Gordon and Ali, Yunus and Jairath, Vipul and Bremner, Stephen and Harhay, Michael O. and Hooper, Richard and Wright, Neil and Eldridge, Sandra M. and Leyrat, Clémence},
	month = sep,
	year = {2016},
	pmid = {27600609},
	pmcid = {PMC5013635},
	file = {PubMed Central Full Text PDF:/Users/jnugent/Zotero/storage/UD3ZZV6P/Kahan et al. - 2016 - Increased risk of type I errors in cluster randomi.pdf:application/pdf}
}

@book{hayes_cluster_2017,
	address = {Boca Raton},
	edition = {2 edition},
	title = {Cluster {Randomised} {Trials}},
	isbn = {978-1-4987-2822-5},
	abstract = {Cluster Randomised Trials, Second Edition discusses the design, conduct, and analysis of trials that randomise groups of individuals to different treatments. It explores the advantages of cluster randomisation, with special attention given to evaluating the effects of interventions against infectious diseases. Avoiding unnecessary mathematical detail, the book covers basic concepts underlying the use of cluster randomisation, such as direct, indirect, and total effects.  In the time since the publication of the first edition, the use of cluster randomised trials (CRTs) has increased substantially, which is reflected in the updates to this edition. There are greatly expanded sections on randomisation, sample size estimation, and alternative designs, including new material on stepped wedge designs. There is a new section on handling ordinal outcome data, and an appendix with descriptions and/or generating code of the example data sets. Although the book mainly focuses on medical and public health applications, it shows that the rigorous evidence of intervention effects provided by CRTs has the potential to inform public policy in a wide range of other areas. The book encourages readers to apply the methods to their own trials, reproduce the analyses presented, and explore alternative approaches.},
	language = {English},
	publisher = {Chapman and Hall/CRC},
	author = {Hayes, Richard J. and Moulton, Lawrence H.},
	month = jun,
	year = {2017}
}

@article{campbell_developments_2007,
	title = {Developments in cluster randomized trials and {Statistics} in {Medicine}},
	volume = {26},
	copyright = {Copyright © 2006 John Wiley \& Sons, Ltd.},
	issn = {1097-0258},
	url = {http://onlinelibrary.wiley.com/doi/abs/10.1002/sim.2731},
	doi = {10.1002/sim.2731},
	abstract = {The design and analysis of cluster randomized trials has been a recurrent theme in Statistics in Medicine since the early volumes. In celebration of 25 years of Statistics in Medicine, this paper reviews recent developments, particularly those that featured in the journal. Issues in design such as sample size calculations, matched paired designs, cohort versus cross-sectional designs, and practical design problems are covered. Developments in analysis include modification of robust methods to cope with small numbers of clusters, generalized estimation equations, population averaged and cluster specific models. Finally, issues on presenting data, some other clustering issues and the general problem of evaluating complex interventions are briefly mentioned. Copyright © 2006 John Wiley \& Sons, Ltd.},
	language = {en},
	number = {1},
	urldate = {2019-10-06},
	journal = {Statistics in Medicine},
	author = {Campbell, M. J. and Donner, A. and Klar, N.},
	year = {2007},
	keywords = {cluster randomized trial, cluster specific models, Consort statement, generalized estimating equations, matched pair design, population averaged models},
	pages = {2--19},
	file = {Full Text PDF:/Users/jnugent/Zotero/storage/NGFPMURG/Campbell et al. - 2007 - Developments in cluster randomized trials and Stat.pdf:application/pdf;Snapshot:/Users/jnugent/Zotero/storage/KDD7TJK5/sim.html:text/html}
}

@book{fitzmaurice_applied_2012,
	edition = {2 edition},
	title = {Applied {Longitudinal} {Analysis}},
	abstract = {Praise for the First Edition ". . . [this book] should be on the shelf of everyone interested in . . . longitudinal data analysis." —Journal of the American Statistical Association Features newly developed topics and applications of the analysis of longitudinal data Applied Longitudinal Analysis, Second Edition presents modern methods for analyzing data from longitudinal studies and now features the latest state-of-the-art techniques. The book emphasizes practical, rather than theoretical, aspects of methods for the analysis of diverse types of longitudinal data that can be applied across various fields of study, from the health and medical sciences to the social and behavioral sciences. The authors incorporate their extensive academic and research experience along with various updates that have been made in response to reader feedback. The Second Edition features six newly added chapters that explore topics currently evolving in the field, including:  Fixed effects and mixed effects models Marginal models and generalized estimating equations Approximate methods for generalized linear mixed effects models Multiple imputation and inverse probability weighted methods Smoothing methods for longitudinal data Sample size and power  Each chapter presents methods in the setting of applications to data sets drawn from the health sciences. New problem sets have been added to many chapters, and a related website features sample programs and computer output using SAS, Stata, and R, as well as data sets and supplemental slides to facilitate a complete understanding of the material. With its strong emphasis on multidisciplinary applications and the interpretation of results, Applied Longitudinal Analysis, Second Edition is an excellent book for courses on statistics in the health and medical sciences at the upper-undergraduate and graduate levels. The book also serves as a valuable reference for researchers and professionals in the medical, public health, and pharmaceutical fields as well as those in social and behavioral sciences who would like to learn more about analyzing longitudinal data.},
	language = {English},
	publisher = {Wiley},
	author = {Fitzmaurice, Garrett M. and Laird, Nan M. and Ware, James H.},
	month = oct,
	year = {2012}
}

@book{kish_survey_1995,
	address = {New York},
	edition = {Revised edition},
	title = {Survey {Sampling}},
	isbn = {978-0-471-10949-5},
	abstract = {An accessible book on sampling techniques with emphasis on and illustrations from surveys of human populations. Explains how to design and execute valid samples of moderate dimensions and difficulty, avoid selection biases and how to become more adept at evaluating sample results, judge their validity and limits of inference, applicability and precision. Contains numerous practical procedures, the domestic arts of sampling along with its science plus invaluable tricks that are usually learned only in apprenticeship.},
	language = {English},
	publisher = {Wiley-Interscience},
	author = {Kish, Leslie},
	month = feb,
	year = {1995}
}

@article{donner_statistical_1996,
	title = {Statistical considerations in the design and analysis of community intervention trials},
	volume = {49},
	issn = {0895-4356},
	url = {http://www.sciencedirect.com/science/article/pii/0895435695005110},
	doi = {10.1016/0895-4356(95)00511-0},
	abstract = {Community intervention trials are often characterized by the allocation of intact social units to different intervention groups. The assessment of adequate sample size for such trials must take into account the statistical dependencies among responses observed within an allocated unit. However, the small numbers of units typically involved in such trials imply that many methods of analysis that have been proposed for analyzing correlated data, particularly in the case of a dichotomous outcome variable, are not applicable to such designs. In this article we investigate this issue and determine the minimum number of units required per group, for the case of both a dichotomous and a continuous outcome variable, needed to provide adequate statistical power for detecting various levels of treatment effect. The use of significance testing as a method of detecting intracluster correlation is also investigated, and, in general, discouraged.},
	number = {4},
	urldate = {2019-10-06},
	journal = {Journal of Clinical Epidemiology},
	author = {Donner, Allan and Klar, Neil},
	month = apr,
	year = {1996},
	keywords = {sample size, Cluster randomization, power},
	pages = {435--439},
	file = {ScienceDirect Full Text PDF:/Users/jnugent/Zotero/storage/GZVWQFEG/Donner and Klar - 1996 - Statistical considerations in the design and analy.pdf:application/pdf;ScienceDirect Snapshot:/Users/jnugent/Zotero/storage/JDHA8P6P/0895435695005110.html:text/html}
}

@book{cox_and_d._v._hinkley_theoretical_1979,
	address = {Boca Raton},
	edition = {1 edition},
	title = {Theoretical {Statistics}},
	isbn = {978-0-412-16160-5},
	abstract = {A text that stresses the general concepts of the theory of statistics Theoretical Statistics provides a systematic statement of the theory of statistics, emphasizing general concepts rather than mathematical rigor. Chapters 1 through 3 provide an overview of statistics and discuss some of the basic philosophical ideas and problems behind statistical procedures. Chapters 4 and 5 cover hypothesis testing with simple and null hypotheses, respectively. Subsequent chapters discuss non-parametrics, interval estimation, point estimation, asymptotics, Bayesian procedure, and deviation theory. Student familiarity with standard statistical techniques is assumed.},
	language = {English},
	publisher = {Chapman \& Hall/CRC},
	author = {Cox {and} D. V. Hinkley, D. R.},
	month = sep,
	year = {1979}
}

@article{satterthwaite_approximate_1946,
	title = {An {Approximate} {Distribution} of {Estimates} of {Variance} {Components}},
	volume = {2},
	issn = {0099-4987},
	url = {http://www.jstor.org/stable/3002019},
	doi = {10.2307/3002019},
	number = {6},
	urldate = {2019-10-06},
	journal = {Biometrics Bulletin},
	author = {Satterthwaite, F. E.},
	year = {1946},
	pages = {110--114}
}

@article{satterthwaite_synthesis_1941,
	title = {Synthesis of variance},
	volume = {6},
	issn = {1860-0980},
	url = {https://doi.org/10.1007/BF02288586},
	doi = {10.1007/BF02288586},
	abstract = {The distribution of a linear combination of two statistics distributed as is Chi-square is studied. The degree of approximation involved in assuming a Chi-square distribution is illustrated for several representative cases. It is concluded that the approximation is sufficiently accurate to use in many practical applications. Illustrations are given of its use in extending the Chi-square, the Student “t” and the Fisher “z” tests to a wider range of problems.},
	language = {en},
	number = {5},
	urldate = {2019-10-06},
	journal = {Psychometrika},
	author = {Satterthwaite, Franklin E.},
	month = oct,
	year = {1941},
	keywords = {Linear Combination, Public Policy, Representative Case, Statistical Theory},
	pages = {309--316}
}

@book{mcculloch_generalized_2008,
	address = {Hoboken, N.J},
	edition = {2 edition},
	title = {Generalized, {Linear}, and {Mixed} {Models}},
	isbn = {978-0-470-07371-1},
	abstract = {An accessible and self-contained introduction to statistical models-now in a modernized new edition  Generalized, Linear, and Mixed Models, Second Edition provides an up-to-date treatment of the essential techniques for developing and applying a wide variety of statistical models. The book presents thorough and unified coverage of the theory behind generalized, linear, and mixed models and highlights their similarities and differences in various construction, application, and computational aspects.  A clear introduction to the basic ideas of fixed effects models, random effects models, and mixed models is maintained throughout, and each chapter illustrates how these models are applicable in a wide array of contexts. In addition, a discussion of general methods for the analysis of such models is presented with an emphasis on the method of maximum likelihood for the estimation of parameters. The authors also provide comprehensive coverage of the latest statistical models for correlated, non-normally distributed data. Thoroughly updated to reflect the latest developments in the field, the Second Edition features:  A new chapter that covers omitted covariates, incorrect random effects distribution, correlation of covariates and random effects, and robust variance estimation A new chapter that treats shared random effects models, latent class models, and properties of models A revised chapter on longitudinal data, which now includes a discussion of generalized linear models, modern advances in longitudinal data analysis, and the use between and within covariate decompositions Expanded coverage of marginal versus conditional models Numerous new and updated examples   With its accessible style and wealth of illustrative exercises, Generalized, Linear, and Mixed Models, Second Edition is an ideal book for courses on generalized linear and mixed models at the upper-undergraduate and beginning-graduate levels. It also serves as a valuable reference for applied statisticians, industrial practitioners, and researchers.},
	language = {English},
	publisher = {Wiley-Interscience},
	author = {McCulloch, Charles E. and Searle, Shayle R. and Neuhaus, John M.},
	month = jun,
	year = {2008}
}